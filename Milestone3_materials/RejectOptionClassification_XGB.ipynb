{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e28fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aif360 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from aif360) (1.23.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from aif360) (1.4.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from aif360) (3.5.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from aif360) (1.9.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from aif360) (1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from pandas>=0.24.0->aif360) (2022.2.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from scikit-learn>=1.0->aif360) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from scikit-learn>=1.0->aif360) (3.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from matplotlib->aif360) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from matplotlib->aif360) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from matplotlib->aif360) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from matplotlib->aif360) (4.36.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from matplotlib->aif360) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from matplotlib->aif360) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\frong\\anaconda3\\envs\\soft_dev\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->aif360) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416eab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "from common_utils_ import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "from tabulate import tabulate\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd96f1",
   "metadata": {},
   "source": [
    "Load Dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf71284",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attribute_used = 0\n",
    "dataset_orig = GermanDataset()\n",
    "if protected_attribute_used == 1:\n",
    "    privileged_groups = [{'sex': 1}]\n",
    "    unprivileged_groups = [{'sex': 0}]\n",
    "    dataset_orig = load_preproc_data_german(['sex'])\n",
    "else:\n",
    "    privileged_groups = [{'age': 1}]\n",
    "    unprivileged_groups = [{'age': 0}]\n",
    "    dataset_orig = load_preproc_data_german(['age'])\n",
    "    \n",
    "        \n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00946f7",
   "metadata": {},
   "source": [
    "Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a7912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99e94c",
   "metadata": {},
   "source": [
    "Clean up training data and display properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037b7608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2791227",
   "metadata": {},
   "source": [
    "## Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5c3f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.119044\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f73f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model\n",
    "model_used = \"XGB\"  # SVC, RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca9dd4",
   "metadata": {},
   "source": [
    "## Train classifier on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e49b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classifier and predictions\n",
    "# scale_orig = StandardScaler()\n",
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "for i, j in enumerate(y_train):\n",
    "    if j == 2.0:\n",
    "        y_train[i] = 1.0\n",
    "    else:\n",
    "        y_train[i] = 0.0\n",
    "\n",
    "if model_used == \"XGB\":\n",
    "    clf_model = XGBClassifier()\n",
    "    clf_model.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "# positive class index\n",
    "# ==================================================\n",
    "if dataset_orig_train.favorable_label == 1.0:\n",
    "    dataset_orig_train_num = 0.\n",
    "else:\n",
    "    dataset_orig_train_num = 1.0\n",
    "# positive class index \n",
    "pos_ind = np.where(clf_model.classes_ == dataset_orig_train_num)[0][0]\n",
    "\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "y_train_pred = dataset_orig_train_pred.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4c2c5",
   "metadata": {},
   "source": [
    "## Obtain scores for validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d62259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_used == \"XGB\":\n",
    "    dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "    # X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
    "    X_valid = dataset_orig_valid_pred.features\n",
    "    y_valid = dataset_orig_valid_pred.labels\n",
    "    # predict on vaidation set\n",
    "    dataset_orig_valid_pred.scores = clf_model.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "    \n",
    "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    # X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "    X_test = dataset_orig_test_pred.features\n",
    "    y_test = dataset_orig_test_pred.labels\n",
    "    # predict on test set\n",
    "    dataset_orig_test_pred.scores = clf_model.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7f5ce",
   "metadata": {},
   "source": [
    "## Find the optimal parameters from the validation set\n",
    "### Best threshold for classification only (no fairness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd427b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced accuracy (no fairness constraints) = 0.6761\n",
      "Optimal classification threshold (no fairness constraints) = 0.6732\n"
     ]
    }
   ],
   "source": [
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = dataset_orig_valid_pred.scores > class_thresh\n",
    "    dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "    dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "    \n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                             dataset_orig_valid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "print(\"Best balanced accuracy (no fairness constraints) = %.4f\" % np.max(ba_arr))\n",
    "print(\"Optimal classification threshold (no fairness constraints) = %.4f\" % best_class_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179fea6b",
   "metadata": {},
   "source": [
    "## Estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c9434df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84171a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.5247\n",
      "Optimal ROC margin = 0.1261\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1785e93a",
   "metadata": {},
   "source": [
    "## Predictions from Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfe2127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6761\n",
      "Statistical parity difference = -0.2240\n",
      "Precision = 0.8906\n",
      "Recall = 0.5229\n",
      "F1 = 0.6590\n",
      "Disparate impact = 0.5172\n",
      "Average odds difference = -0.0947\n",
      "Equal opportunity difference = -0.0253\n",
      "Theil index = 0.4491\n"
     ]
    }
   ],
   "source": [
    "fav_inds = dataset_orig_valid_pred.scores > best_class_thresh\n",
    "dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "\n",
    "display(Markdown(\"#### Validation set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "metric_valid_bef = compute_metrics(dataset_orig_valid, dataset_orig_valid_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e93475e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6457\n",
      "Statistical parity difference = 0.0480\n",
      "Precision = 0.8472\n",
      "Recall = 0.5596\n",
      "F1 = 0.6740\n",
      "Disparate impact = 1.1017\n",
      "Average odds difference = 0.1836\n",
      "Equal opportunity difference = 0.2646\n",
      "Theil index = 0.4182\n"
     ]
    }
   ],
   "source": [
    "# Transform the validation set\n",
    "dataset_transf_valid_pred = ROC.predict(dataset_orig_valid_pred)\n",
    "\n",
    "display(Markdown(\"#### Validation set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_valid_aft = compute_metrics(dataset_orig_valid, dataset_transf_valid_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31efaa",
   "metadata": {},
   "source": [
    "### Predictions from Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaa35103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6238\n",
      "Statistical parity difference = -0.2278\n",
      "Precision = 0.8026\n",
      "Recall = 0.5810\n",
      "F1 = 0.6740\n",
      "Disparate impact = 0.5853\n",
      "Average odds difference = -0.2016\n",
      "Equal opportunity difference = -0.2318\n",
      "Theil index = 0.3867\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "fav_inds = dataset_orig_test_pred.scores > best_class_thresh\n",
    "dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4efd0988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6190\n",
      "Statistical parity difference = 0.0937\n",
      "Precision = 0.7882\n",
      "Recall = 0.6381\n",
      "F1 = 0.7053\n",
      "Disparate impact = 1.1706\n",
      "Average odds difference = 0.1151\n",
      "Equal opportunity difference = 0.1015\n",
      "Theil index = 0.3350\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_test_pred = ROC.predict(dataset_orig_test_pred)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8721ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Summary of Optimal Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### We show the optimal parameters for all combinations of metrics optimized, dataset, and protected attributes below"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Fairness Metric: Statistical parity difference, Accuracy Metric: Balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Performance metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤════════════════╤════════════════╤═════════════════╤═════════════════╕\n",
      "│ Dataset       │   Age(Acc-Bef) │   Age(Acc-Aft) │   Age(Fair-Bef) │   Age(Fair-Aft) │\n",
      "╞═══════════════╪════════════════╪════════════════╪═════════════════╪═════════════════╡\n",
      "│ German(Valid) │         0.6761 │         0.6457 │         -0.0947 │          0.1836 │\n",
      "├───────────────┼────────────────┼────────────────┼─────────────────┼─────────────────┤\n",
      "│ German(Test)  │         0.6238 │         0.6190 │         -0.2016 │          0.1151 │\n",
      "╘═══════════════╧════════════════╧════════════════╧═════════════════╧═════════════════╛\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Fairness Metric: Average odds difference, Accuracy Metric: Balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Performance metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤════════════════╤════════════════╤═════════════════╤═════════════════╕\n",
      "│ Dataset       │   Age(Acc-Bef) │   Age(Acc-Aft) │   Age(Fair-Bef) │   Age(Fair-Aft) │\n",
      "╞═══════════════╪════════════════╪════════════════╪═════════════════╪═════════════════╡\n",
      "│ German(Valid) │         0.6761 │         0.6457 │         -0.2240 │          0.0480 │\n",
      "├───────────────┼────────────────┼────────────────┼─────────────────┼─────────────────┤\n",
      "│ German(Test)  │         0.6238 │         0.6190 │         -0.2278 │          0.0937 │\n",
      "╘═══════════════╧════════════════╧════════════════╧═════════════════╧═════════════════╛\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Fairness Metric: Equal opportunity difference, Accuracy Metric: Balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model used: XGB\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Performance metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤════════════════╤════════════════╤═════════════════╤═════════════════╕\n",
      "│ Dataset       │   Age(Acc-Bef) │   Age(Acc-Aft) │   Age(Fair-Bef) │   Age(Fair-Aft) │\n",
      "╞═══════════════╪════════════════╪════════════════╪═════════════════╪═════════════════╡\n",
      "│ German(Valid) │         0.6761 │         0.6457 │         -0.0253 │          0.2646 │\n",
      "├───────────────┼────────────────┼────────────────┼─────────────────┼─────────────────┤\n",
      "│ German(Test)  │         0.6238 │         0.6190 │         -0.2318 │          0.1015 │\n",
      "╘═══════════════╧════════════════╧════════════════╧═════════════════╧═════════════════╛\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Optimal Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤════════════════════════╤═══════════════════════════════════╤═══════════════════════════════╕\n",
      "│ Dataset   │   Age (Class. thresh.) │   Age (Class. thresh. - fairness) │   Age (ROC margin - fairness) │\n",
      "╞═══════════╪════════════════════════╪═══════════════════════════════════╪═══════════════════════════════╡\n",
      "│ German    │                 0.6732 │                            0.5247 │                        0.1261 │\n",
      "╘═══════════╧════════════════════════╧═══════════════════════════════════╧═══════════════════════════════╛\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Performance metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤════════════╤═════════════╤══════════╤════════╕\n",
      "│ Reweighting   │   Accuracy │   Precision │   Recall │     F1 │\n",
      "╞═══════════════╪════════════╪═════════════╪══════════╪════════╡\n",
      "│ Before        │     0.6761 │      0.8906 │   0.5229 │ 0.6590 │\n",
      "├───────────────┼────────────┼─────────────┼──────────┼────────┤\n",
      "│ After         │     0.6190 │      0.7882 │   0.6381 │ 0.7053 │\n",
      "╘═══════════════╧════════════╧═════════════╧══════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## Summary of Optimal Parameters\"))\n",
    "display(Markdown(\"### We show the optimal parameters for all combinations of metrics optimized, dataset, and protected attributes below\"))\n",
    "display(Markdown(\"#### Fairness Metric: Statistical parity difference, Accuracy Metric: Balanced accuracy\"))\n",
    "performance_table = {\n",
    "    'Dataset': [\"German(Valid)\", \"German(Test)\"],\n",
    "    'Age(Acc-Bef)': [metric_valid_bef[\"Balanced accuracy\"],metric_test_bef[\"Balanced accuracy\"]],\n",
    "    'Age(Acc-Aft)' : [metric_valid_aft[\"Balanced accuracy\"],metric_test_aft[\"Balanced accuracy\"]],\n",
    "    'Age(Fair-Bef)' : [metric_valid_bef[\"Average odds difference\"], metric_test_bef[\"Average odds difference\"]],\n",
    "    'Age(Fair-Aft)' : [metric_valid_aft[\"Average odds difference\"],metric_test_aft[\"Average odds difference\"]]\n",
    "    \n",
    "}\n",
    "\n",
    "#print(f'\\nModel used: {model_used}')\n",
    "display(Markdown(\"#### Performance metrics\"))\n",
    "print(tabulate(performance_table, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))\n",
    "display(Markdown(\"#### Fairness Metric: Average odds difference, Accuracy Metric: Balanced accuracy\"))\n",
    "performance_table = {\n",
    "    'Dataset': [\"German(Valid)\", \"German(Test)\"],\n",
    "    'Age(Acc-Bef)': [metric_valid_bef[\"Balanced accuracy\"],metric_test_bef[\"Balanced accuracy\"]],\n",
    "    'Age(Acc-Aft)' : [metric_valid_aft[\"Balanced accuracy\"],metric_test_aft[\"Balanced accuracy\"]],\n",
    "    'Age(Fair-Bef)' : [metric_valid_bef[\"Statistical parity difference\"], metric_test_bef[\"Statistical parity difference\"]],\n",
    "    'Age(Fair-Aft)' : [metric_valid_aft[\"Statistical parity difference\"],metric_test_aft[\"Statistical parity difference\"]]\n",
    "    \n",
    "}\n",
    "#print(f'\\nModel used: {model_used}')\n",
    "display(Markdown(\"#### Performance metrics\"))\n",
    "print(tabulate(performance_table, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))\n",
    "\n",
    "display(Markdown(\"#### Fairness Metric: Equal opportunity difference, Accuracy Metric: Balanced accuracy\"))\n",
    "performance_table = {\n",
    "    'Dataset': [\"German(Valid)\", \"German(Test)\"],\n",
    "    'Age(Acc-Bef)': [metric_valid_bef[\"Balanced accuracy\"],metric_test_bef[\"Balanced accuracy\"]],\n",
    "    'Age(Acc-Aft)' : [metric_valid_aft[\"Balanced accuracy\"],metric_test_aft[\"Balanced accuracy\"]],\n",
    "    'Age(Fair-Bef)' : [metric_valid_bef[\"Equal opportunity difference\"], metric_test_bef[\"Equal opportunity difference\"]],\n",
    "    'Age(Fair-Aft)' : [metric_valid_aft[\"Equal opportunity difference\"],metric_test_aft[\"Equal opportunity difference\"]]\n",
    "    \n",
    "}\n",
    "print(f'\\nModel used: {model_used}')\n",
    "display(Markdown(\"#### Performance metrics\"))\n",
    "print(tabulate(performance_table, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))\n",
    "\n",
    "optimal_table = {\n",
    "    'Dataset' : [\"German\"],\n",
    "    'Age (Class. thresh.)' : [best_class_thresh],\n",
    "    'Age (Class. thresh. - fairness)': [ROC.classification_threshold],\n",
    "    'Age (ROC margin - fairness)' : [ROC.ROC_margin]\n",
    "}\n",
    "\n",
    "display(Markdown(\"#### Optimal Parameters\"))\n",
    "print(tabulate(optimal_table, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))\n",
    "\n",
    "performance_table = {\n",
    "    'Reweighting': [\"Before\", \"After\"],\n",
    "    'Accuracy': [metric_valid_bef[\"Balanced accuracy\"], metric_test_aft[\"Balanced accuracy\"]],\n",
    "    'Precision' : [metric_valid_bef[\"Precision\"], metric_test_aft[\"Precision\"]],\n",
    "    'Recall' : [metric_valid_bef[\"Recall\"], metric_test_aft[\"Recall\"]],\n",
    "    'F1' : [metric_valid_bef[\"F1\"], metric_test_aft[\"F1\"]],\n",
    "}\n",
    "\n",
    "display(Markdown(\"#### Performance metrics\"))\n",
    "print(tabulate(performance_table, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d1fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
