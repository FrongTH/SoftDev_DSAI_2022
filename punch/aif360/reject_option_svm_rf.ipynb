{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:dlopen(/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n",
      "  Referenced from: <346F52D5-3FB3-3E9B-86A7-99AFC2266C4F> /Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n",
      "  Reason: tried: '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache): AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:dlopen(/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n",
      "  Referenced from: <346F52D5-3FB3-3E9B-86A7-99AFC2266C4F> /Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n",
      "  Reason: tried: '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../../../_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Peeradon/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Peeradon/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache): AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import psutil\n",
    "from tabulate import tabulate\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils  import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_german\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "# models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used = \"RF\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_preproc_data_german(['age'])\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivilege_groups = [{'age': 0}]\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_train_set, og_vt_set = dataset.split([0.7], shuffle=True)\n",
    "og_valid_set, og_test_set = og_vt_set.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(og_train_set.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(og_train_set.favorable_label, og_train_set.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(og_train_set.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(og_train_set.privileged_protected_attributes,\n",
    "      og_train_set.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(og_train_set.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset mean difference: -0.1452\n"
     ]
    }
   ],
   "source": [
    "og_diff_mean = BinaryLabelDatasetMetric(og_train_set, privileged_groups=privileged_groups, unprivileged_groups=unprivilege_groups)\n",
    "\n",
    "og_diff_mean_value = og_diff_mean.mean_difference()\n",
    "\n",
    "print(\"Original Dataset mean difference: %.4f\" % og_diff_mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = og_train_set.labels.ravel()\n",
    "\n",
    "if model_used == \"SVC\":\n",
    "    clf_model = LinearSVC()\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(og_train_set.features)\n",
    "if model_used == \"RF\":\n",
    "    clf_model = RandomForestClassifier()\n",
    "    X_train = og_train_set.features\n",
    "\n",
    "# ==================================================\n",
    "timer_str = time.time()\n",
    "mem_str = psutil.Process().memory_info().rss / (1024 * 1024)\n",
    "\n",
    "clf_model.fit(X_train, y_train, sample_weight=og_train_set.instance_weights)\n",
    "\n",
    "timer_stp = time.time()\n",
    "mem_stp = psutil.Process().memory_info().rss / (1024 * 1024)\n",
    "\n",
    "og_train_time = timer_stp - timer_str\n",
    "og_train_mem = mem_stp - mem_str\n",
    "\n",
    "# ==================================================\n",
    "# positive class index \n",
    "pos_ind = np.where(clf_model.classes_ == og_train_set.favorable_label)[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores for validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_valid_set_pred = og_valid_set.copy(deepcopy=True)\n",
    "og_test_pred = og_test_set.copy(deepcopy=True)\n",
    "\n",
    "y_valid = og_valid_set_pred.labels\n",
    "y_test = og_test_pred.labels\n",
    "\n",
    "if model_used == \"SVC\":\n",
    "    X_valid = scaler.fit_transform(og_valid_set_pred.features)\n",
    "    # predict on vaidation set\n",
    "    og_valid_set_pred.scores = clf_model._predict_proba_lr(X_valid)[:, pos_ind].reshape(-1,1)\n",
    "\n",
    "    X_test = scaler.fit_transform(og_test_pred.features)\n",
    "    # predict on test set\n",
    "    og_test_pred.scores = clf_model._predict_proba_lr(X_test)[:, pos_ind].reshape(-1,1)\n",
    "\n",
    "if model_used == \"RF\":\n",
    "    X_valid = og_valid_set_pred.features\n",
    "    og_valid_set_pred.scores = clf_model.predict_proba(X_valid)[:, pos_ind].reshape(-1,1)\n",
    "\n",
    "    X_test = og_test_pred.features\n",
    "    og_test_pred.scores = clf_model.predict_proba(X_test)[:, pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the optimal parameter from validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best threshold (no fairness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced accuracy (no fairness constraint) = 0.7148\n",
      "Best recall (no fairness constraint) = 1.0000\n",
      "Optimal threshold based on accuracy = 0.6930\n",
      "Optimal threshold based on recall = 0.6930 \n"
     ]
    }
   ],
   "source": [
    "# Find optimal threshold based on balanced accuracy\n",
    "num_thresh = 100    # 0.00 - 1.00\n",
    "ba_acc = np.zeros(num_thresh)   # balance accuracy for each threshold\n",
    "recall_acc = np.zeros(num_thresh)   # recall for each threshold\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)  # search space \n",
    "\n",
    "for idx, threshold in enumerate(class_thresh_arr):\n",
    "    # set labels if probability > threshold \n",
    "    fav_inds = og_valid_set_pred.scores > threshold\n",
    "    og_valid_set_pred.labels[fav_inds] = og_valid_set_pred.favorable_label\n",
    "    og_valid_set_pred.labels[~fav_inds] = og_valid_set_pred.unfavorable_label\n",
    "\n",
    "    # classified metric \n",
    "    og_valid_class_met = ClassificationMetric(og_valid_set, og_valid_set_pred, privileged_groups=privileged_groups, unprivileged_groups=unprivilege_groups)\n",
    "\n",
    "    ba_acc[idx] = 0.5 * (og_valid_class_met.true_positive_rate() + og_valid_class_met.true_negative_rate())\n",
    "\n",
    "    recall_acc[idx] = og_valid_class_met.recall()\n",
    "\n",
    "best_idx_acc = np.where(ba_acc == np.max(ba_acc))[0][0]\n",
    "best_idx_recall = np.where(recall_acc == np.max(recall_acc))[0][0]\n",
    "\n",
    "best_class_thresh_acc = class_thresh_arr[best_idx_acc]\n",
    "best_class_thresh_recall = class_thresh_arr[best_idx_acc]\n",
    "\n",
    "print(\"Best balanced accuracy (no fairness constraint) = %.4f\" % np.max(ba_acc))\n",
    "print(\"Best recall (no fairness constraint) = %.4f\" % np.max(recall_acc))\n",
    "\n",
    "print(\"Optimal threshold based on accuracy = %.4f\" % best_class_thresh_acc)\n",
    "print(\"Optimal threshold based on recall = %.4f \" % best_class_thresh_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate optimal parameter for ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivilege_groups,\n",
    "                                 privileged_groups=privileged_groups,\n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                 num_class_thresh=100, num_ROC_margin=50,\n",
    "                                 metric_name=\"Statistical parity difference\",metric_ub=0.05, metric_lb=-0.05)\n",
    "ROC = ROC.fit(og_valid_set, og_valid_set_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness) = 0.6930\n",
      "Optimal ROC margin = 0.0626\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7148\n",
      "Precision = 0.9091\n",
      "Recall = 0.5660\n",
      "F1 = 0.6977\n",
      "Disparate impact = 0.5598\n",
      "Average odds difference = -0.1207\n",
      "Statistical parity difference = -0.2145\n",
      "Equal opportunity difference = -0.2663\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "fav_inds = og_valid_set_pred.scores > best_class_thresh_acc\n",
    "og_valid_set_pred.labels[fav_inds] = og_valid_set_pred.favorable_label\n",
    "og_valid_set_pred.labels[~fav_inds] = og_valid_set_pred.unfavorable_label\n",
    "\n",
    "display(Markdown(\"#### Validation set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "metric_valid_bef = compute_metrics(og_valid_set, og_valid_set_pred, \n",
    "                unprivilege_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7082\n",
      "Precision = 0.8971\n",
      "Recall = 0.5755\n",
      "F1 = 0.7011\n",
      "Disparate impact = 0.9192\n",
      "Average odds difference = 0.0589\n",
      "Statistical parity difference = -0.0373\n",
      "Equal opportunity difference = -0.0930\n"
     ]
    }
   ],
   "source": [
    "# Transform the validation set\n",
    "dataset_transf_valid_pred = ROC.predict(og_valid_set_pred)\n",
    "\n",
    "display(Markdown(\"#### Validation set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_valid_aft = compute_metrics(og_valid_set, dataset_transf_valid_pred, \n",
    "                unprivilege_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction from Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6158\n",
      "Precision = 0.8103\n",
      "Recall = 0.4608\n",
      "F1 = 0.5875\n",
      "Disparate impact = 0.4298\n",
      "Average odds difference = -0.2059\n",
      "Statistical parity difference = -0.2457\n",
      "Equal opportunity difference = -0.2029\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "fav_inds = og_test_pred.scores > best_class_thresh_acc\n",
    "og_test_pred.labels[fav_inds] = og_test_pred.favorable_label\n",
    "og_test_pred.labels[~fav_inds] = og_test_pred.unfavorable_label\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "metric_test_bef = compute_metrics(og_test_set, og_test_pred, \n",
    "                unprivilege_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6011\n",
      "Precision = 0.8000\n",
      "Recall = 0.4314\n",
      "F1 = 0.5605\n",
      "Disparate impact = 0.6644\n",
      "Average odds difference = -0.0947\n",
      "Statistical parity difference = -0.1310\n",
      "Equal opportunity difference = -0.0860\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_test_pred = ROC.predict(og_test_pred)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_test_aft = compute_metrics(og_test_set, dataset_transf_test_pred, \n",
    "                unprivilege_groups, privileged_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model used: RF\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Performance metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════╤════════════╤═════════════╤══════════╤════════╤═════════════════════╤══════════╕\n",
      "│ ROC    │   Accuracy │   Precision │   Recall │     F1 │ Time                │ Memory   │\n",
      "╞════════╪════════════╪═════════════╪══════════╪════════╪═════════════════════╪══════════╡\n",
      "│ Before │     0.6158 │      0.8103 │   0.4608 │ 0.5875 │ 0.08228874206542969 │ 1.09375  │\n",
      "├────────┼────────────┼─────────────┼──────────┼────────┼─────────────────────┼──────────┤\n",
      "│ After  │     0.6011 │      0.8000 │   0.4314 │ 0.5605 │ -                   │ -        │\n",
      "╘════════╧════════════╧═════════════╧══════════╧════════╧═════════════════════╧══════════╛\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════╤═══════════════════════════╤═════════════════════════════════╤═══════════════════════════════╕\n",
      "│ ROC    │   Average Odds Difference │   Statistical parity difference │   Equal opportuniy difference │\n",
      "╞════════╪═══════════════════════════╪═════════════════════════════════╪═══════════════════════════════╡\n",
      "│ Before │                   -0.2059 │                         -0.2457 │                       -0.2029 │\n",
      "├────────┼───────────────────────────┼─────────────────────────────────┼───────────────────────────────┤\n",
      "│ After  │                   -0.0947 │                         -0.1310 │                       -0.0860 │\n",
      "╘════════╧═══════════════════════════╧═════════════════════════════════╧═══════════════════════════════╛\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Noted for the classification to be fair"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact(DI): higher is better.\n",
      "Average odds difference(AOD): must be close to zero.\n",
      "Statistical Parity Difference(SPD): must be equal to zero.\n",
      "Equal Opportunity Difference(EOD): must be equal to zero.\n",
      "Source: https://www.mathworks.com/help/risk/explore-fairness-metrics-for-credit-scoring-model.html\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## Summary\"))\n",
    "\n",
    "performance_table = {\n",
    "    'ROC': [\"Before\", \"After\"],\n",
    "    'Accuracy': [metric_test_bef[\"Balanced accuracy\"], metric_test_aft[\"Balanced accuracy\"]],\n",
    "    'Precision' : [metric_test_bef[\"Precision\"], metric_test_aft[\"Precision\"]],\n",
    "    'Recall' : [metric_test_bef[\"Recall\"], metric_test_aft[\"Recall\"]],\n",
    "    'F1' : [metric_test_bef[\"F1\"], metric_test_aft[\"F1\"]],\n",
    "    'Time' : [og_train_time, \"-\"],\n",
    "    'Memory' : [og_train_mem, \"-\"]\n",
    "}\n",
    "\n",
    "print(f'\\nModel used: {model_used}')\n",
    "display(Markdown(\"#### Performance metrics\"))\n",
    "print(tabulate(performance_table, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))\n",
    "\n",
    "fairness_table = {\n",
    "    'ROC' : [\"Before\", \"After\"],\n",
    "    'Average Odds Difference' : [metric_test_bef[\"Average odds difference\"], metric_test_aft[\"Average odds difference\"]],\n",
    "    'Statistical parity difference' : [metric_test_bef[\"Statistical parity difference\"], metric_test_aft[\"Statistical parity difference\"]],\n",
    "    'Equal opportuniy difference' : [metric_test_bef[\"Equal opportunity difference\"], metric_test_aft[\"Equal opportunity difference\"]]\n",
    "}\n",
    "\n",
    "display(Markdown(\"#### Fairness metrics\"))\n",
    "print(tabulate(fairness_table, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))\n",
    "display(Markdown(\"##### Noted for the classification to be fair\"))\n",
    "print(\"Disparate impact(DI): higher is better.\\nAverage odds difference(AOD): must be close to zero.\\nStatistical Parity Difference(SPD): must be equal to zero.\\nEqual Opportunity Difference(EOD): must be equal to zero.\")\n",
    "print(\"Source: https://www.mathworks.com/help/risk/explore-fairness-metrics-for-credit-scoring-model.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f995c52911191224c4e02ed15d46d239801bb9bed64226067616b7558227c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
